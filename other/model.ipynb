{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import json\n",
    "import math\n",
    "from typing import Tuple, TypeVar\n",
    "import warnings\n",
    "\n",
    "import haiku as hk\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotnine as gg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "T = TypeVar('T')\n",
    "Pair = Tuple[T, T]\n",
    "\n",
    "gg.theme_set(gg.theme_bw())\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from a JSON file\n",
    "with open('braille_translation.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "bin_to_braille = data['bin_to_braille']\n",
    "eng_to_bin = data['eng_to_bin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_character(char: str) -> int:\n",
    "    \"\"\"Encode a single character to its ASCII value.\"\"\"\n",
    "    return ord(char)\n",
    "\n",
    "def decode_character(code: int) -> str:\n",
    "    \"\"\"Decode an ASCII value back to a character.\"\"\"\n",
    "    return chr(code)\n",
    "\n",
    "def encode_braille_binary(binary_str: str) -> np.ndarray:\n",
    "    \"\"\"Encode a Braille binary string to an array of integers.\"\"\"\n",
    "    return np.array([int(bit) for bit in binary_str], dtype=np.int32)\n",
    "\n",
    "# Example decoding function for Braille (you might need to adjust this based on your model's output)\n",
    "def decode_braille_binary(binary_array: np.ndarray) -> str:\n",
    "    \"\"\"Decode an array of integers back to a Braille binary string.\"\"\"\n",
    "    return ''.join(map(str, binary_array))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_braille_data(seq_len: int, data_size: int) -> Pair[np.ndarray]:\n",
    "    english_chars = list(eng_to_bin.keys())\n",
    "    eng_seqs = np.random.choice(english_chars, (data_size, seq_len))\n",
    "\n",
    "    # Encode English sequences\n",
    "    vectorized_encode_char = np.vectorize(encode_character)\n",
    "    encoded_eng_seqs = vectorized_encode_char(eng_seqs)\n",
    "    # Assuming encoded_eng_seqs is of shape [data_size, seq_len]\n",
    "    encoded_eng_seqs = encoded_eng_seqs[:, :, np.newaxis]  # Now shape [data_size, seq_len, 1]\n",
    "\n",
    "\n",
    "    # Encode Braille sequences\n",
    "    braille_seqs = np.vectorize(eng_to_bin.get)(eng_seqs)\n",
    "    vectorized_encode_braille = np.vectorize(encode_braille_binary, signature='()->(n)')\n",
    "    encoded_braille_seqs = vectorized_encode_braille(braille_seqs)\n",
    "\n",
    "    return encoded_eng_seqs, encoded_braille_seqs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(eng_seqs, braille_seqs, train_size, valid_size):\n",
    "    # Split the data into training and validation sets\n",
    "    train_x = eng_seqs[:train_size]\n",
    "    train_y = braille_seqs[:train_size]\n",
    "\n",
    "    valid_x = eng_seqs[train_size:train_size + valid_size]\n",
    "    valid_y = braille_seqs[train_size:train_size + valid_size]\n",
    "\n",
    "    return (train_x, train_y), (valid_x, valid_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    \"\"\"An iterator over a dataset, revealing batch_size elements at a time.\"\"\"\n",
    "\n",
    "    def __init__(self, xy: Pair[np.ndarray], batch_size: int):\n",
    "        self._x, self._y = xy\n",
    "        self._batch_size = batch_size\n",
    "        self._num_batches = self._x.shape[0] // batch_size\n",
    "        self._idx = 0\n",
    "\n",
    "    def __next__(self) -> Pair[np.ndarray]:\n",
    "        if self._idx >= self._num_batches:\n",
    "            raise StopIteration\n",
    "\n",
    "        start = self._idx * self._batch_size\n",
    "        end = start + self._batch_size\n",
    "        x, y = self._x[start:end], self._y[start:end]\n",
    "        self._idx += 1\n",
    "        return x, y\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "repetitions = 500\n",
    "BATCH_SIZE = 8  # Number of examples per batch\n",
    "SEQ_LEN = 64  # Length of each sequence\n",
    "DATA_SIZE = 27 * repetitions  # where repetitions is the number of times you repeat the dataset\n",
    "TRAIN_SIZE = int(0.75 * DATA_SIZE)  # Example: 75% for training\n",
    "VALID_SIZE = DATA_SIZE - TRAIN_SIZE  # Remaining for validation\n",
    "# Generate the data\n",
    "eng_seqs, braille_seqs = generate_braille_data(SEQ_LEN, DATA_SIZE)\n",
    "\n",
    "# Split the data\n",
    "train, valid = split_data(eng_seqs, braille_seqs, TRAIN_SIZE, VALID_SIZE)\n",
    "\n",
    "# Create dataset objects\n",
    "train_ds = Dataset(train, BATCH_SIZE)\n",
    "valid_ds = Dataset(valid, BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unroll_net(seqs: jnp.ndarray):\n",
    "    core = hk.LSTM(128)\n",
    "    batch_size = seqs.shape[1]\n",
    "    outs, state = hk.dynamic_unroll(core, seqs, core.initial_state(batch_size))\n",
    "    return hk.BatchApply(hk.Linear(6))(outs), state\n",
    "\n",
    "\n",
    "model = hk.transform(unroll_net)\n",
    "\n",
    "\n",
    "def train_model(train_ds: Dataset) -> hk.Params:\n",
    "    \"\"\"Initializes and trains a model on train_ds, returning the final params.\"\"\"\n",
    "    rng = jax.random.PRNGKey(428)\n",
    "    opt = optax.adam(1e-3)\n",
    "\n",
    "    @jax.jit\n",
    "    def loss(params, x, y):\n",
    "        pred, _ = model.apply(params, None, x)\n",
    "        # Use binary cross-entropy loss\n",
    "        return jnp.mean(optax.sigmoid_binary_cross_entropy(pred, y))\n",
    "\n",
    "    @jax.jit\n",
    "    def update(step, params, opt_state, x, y):\n",
    "        l, grads = jax.value_and_grad(loss)(params, x, y)\n",
    "        grads, opt_state = opt.update(grads, opt_state)\n",
    "        params = optax.apply_updates(params, grads)\n",
    "        return l, params, opt_state\n",
    "\n",
    "    # Initialize state.\n",
    "    sample_x, _ = next(train_ds)\n",
    "    params = model.init(rng, sample_x)\n",
    "    opt_state = opt.init(params)\n",
    "\n",
    "    for step in range(1000):\n",
    "        try:\n",
    "            x, y = next(train_ds)\n",
    "        except StopIteration:\n",
    "            break \n",
    "        train_loss, params, opt_state = update(step, params, opt_state, x, y)\n",
    "        if step % 100 == 0:\n",
    "            print(\"Step {}: train loss {}\".format(step, train_loss))\n",
    "\n",
    "    return params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: train loss 0.6983954310417175\n",
      "Step 100: train loss 0.576724648475647\n",
      "Step 200: train loss 0.5514483451843262\n",
      "Step 300: train loss 0.5117329955101013\n",
      "Step 400: train loss 0.508243203163147\n",
      "Step 500: train loss 0.5050299167633057\n",
      "Step 600: train loss 0.4777008891105652\n",
      "Step 700: train loss 0.48730605840682983\n",
      "Step 800: train loss 0.48745638132095337\n",
      "Step 900: train loss 0.4798251986503601\n"
     ]
    }
   ],
   "source": [
    "trained_params = train_model(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_braille(model, trained_params, encoded_char):\n",
    "    # The input encoded_char should already be in shape [1, 1, 1]\n",
    "    pred, _ = model.apply(trained_params, None, encoded_char)\n",
    "    # Apply sigmoid and round to get binary values\n",
    "    pred_binary = jnp.round(jax.nn.sigmoid(pred))\n",
    "    return pred_binary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_char = 'c'  # Example character\n",
    "encoded_input = encode_character(input_char)\n",
    "\n",
    "# Reshape to [1, 1, 1] for [batch_size, sequence_length, features]\n",
    "encoded_input = jnp.array([[[encoded_input]]], dtype=jnp.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[[99.]]'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_braille_binary(encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
